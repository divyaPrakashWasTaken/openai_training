{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SROMV73xLQ-g",
        "outputId": "504bf9fc-7ef8-4fc6-83de-89bb71199576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.13.3)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import asyncio\n",
        "from openai import AsyncAzureOpenAI\n",
        "import requests\n"
      ],
      "metadata": {
        "id": "5Z4rtXoPLWty"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration settings\n",
        "azure_oai_endpoint =\"https://eyuser20.openai.azure.com/\"\n",
        "azure_oai_key =\"1379196e9ab94ff6995d28aa0a9ca9f2\"\n",
        "azure_oai_deployment =\"GPT-35\""
      ],
      "metadata": {
        "id": "EBIlebGvLZCH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the Azure OpenAI client\n",
        "client = AsyncAzureOpenAI(\n",
        "    azure_endpoint=azure_oai_endpoint,\n",
        "    api_key=azure_oai_key,\n",
        "    api_version=\"2024-02-15-preview\"\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Azure OpenAI client configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU3rQ6ynLgYc",
        "outputId": "82c7d6f0-c5e6-4c43-8a69-19629a3bfbb1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Azure OpenAI client configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set to True to print the full response from OpenAI for each call\n",
        "printFullResponse = False\n",
        "\n",
        "async def main():\n",
        "    try:\n",
        "        while True:\n",
        "            system_text = \"You are a helpful medical bot with expertise in medical field.\"\n",
        "            print(\"Enter 1 to chat 2 to generate image 3 to exit\")\n",
        "            choice = int(input(\"Enter your choice: \"))\n",
        "            if(choice == 1):\n",
        "                user_text = input(\"Enter user message: \")\n",
        "                await call_openai_model(system_message=system_text,\n",
        "                                        user_message=user_text,\n",
        "                                        model=azure_oai_deployment,\n",
        "                                        client=client)\n",
        "            elif(choice == 2):\n",
        "                prompt = input(\"Enter image prompt: \")\n",
        "                image_url = await call_dalle_model(prompt)\n",
        "                print(image_url)\n",
        "            else:\n",
        "                print('Exiting program...')\n",
        "                break\n",
        "\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "metadata": {
        "id": "CHs2rbLqLjov"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def call_openai_model(system_message, user_message, model, client):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": \"What should I do if I have toothache\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"When you have a tootache, vist a dentist and get your teeth checked. Brush your teeth regurlary and twice a day\"},\n",
        "        {\"role\": \"user\", \"content\": \"What kind of exercises can i do for alleviating back pain?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"To alleviate the back pain you should regulary do exercises for both the upper and lower back. You can do planks, crunches, leg raises and deadlift\"},\n",
        "        {\"role\": \"user\", \"content\": user_message},\n",
        "        ]\n",
        "    print(\"Sending request to Azure OpenAI model...\")\n",
        "    # Call the Azure OpenAI model\n",
        "    response = await client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7,\n",
        "        max_tokens=800\n",
        "    )\n",
        "\n",
        "    if printFullResponse:\n",
        "        print(response)\n",
        "\n",
        "    print(\"Response:\" + response.choices[0].message.content + \"\\n\")"
      ],
      "metadata": {
        "id": "Ihj6Mq7EMAdl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def call_dalle_model(prompt):\n",
        "    dalle_azure_oai_endpoint =\"https://eyuser3.openai.azure.com/\"\n",
        "    dalle_azure_oai_key =\"06f6ae63b2f94f23b2c39ec67a612ee8\"\n",
        "    dalle_azure_oai_deployment =\"Dalle3\"\n",
        "    api_version=\"2024-02-15-preview\"\n",
        "    url = \"{}openai/deployments/dalle3/images/generations?api-version={}\".format(dalle_azure_oai_endpoint, api_version)\n",
        "    headers= { \"api-key\": dalle_azure_oai_key, \"Content-Type\": \"application/json\" }\n",
        "    body = {\n",
        "                \"prompt\": prompt,\n",
        "                \"n\": 1,\n",
        "                \"size\": \"1024x1024\"\n",
        "            }\n",
        "    response = requests.post(url, headers=headers, json=body)\n",
        "    print(response.text)\n",
        "      # Get the revised prompt and image URL from the response\n",
        "    revised_prompt = response.json()['data'][0]['revised_prompt']\n",
        "    image_url = response.json()['data'][0]['url']\n",
        "\n",
        "    # Display the URL for the generated image\n",
        "    print(revised_prompt)\n",
        "    print(image_url)\n",
        "    return image_url"
      ],
      "metadata": {
        "id": "jocgY9uKMx_r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvahYEd4MJ2B",
        "outputId": "1501c735-9c23-4658-8faa-0eb853a3f2b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter 1 to chat 2 to generate image 3 to exit\n",
            "Enter your choice: 2\n",
            "Enter image prompt: x-ray image of human chest\n",
            "{\"created\":1718192587,\"data\":[{\"content_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}},\"prompt_filter_results\":{\"hate\":{\"filtered\":false,\"severity\":\"safe\"},\"profanity\":{\"detected\":false,\"filtered\":false},\"self_harm\":{\"filtered\":false,\"severity\":\"safe\"},\"sexual\":{\"filtered\":false,\"severity\":\"safe\"},\"violence\":{\"filtered\":false,\"severity\":\"safe\"}},\"revised_prompt\":\"An x-ray image showcasing the human chest. The radiography must consist of the sternum (breastbone) in the center, the ribcage surrounding it, the clavicle (collarbone) at the top, and the heart and lungs visible as darker areas. The lung fields must look symmetrical on each side. The faint white branching structures might be the bronchial tree. The image contains shades of grey, where denser structures like the bone appear whiter. The setting must elude a radiology department with the x-ray positioned on an illuminated panel for viewing.\",\"url\":\"https://dalleproduse.blob.core.windows.net/private/images/e41b776c-27a5-43f3-b527-a98be3068dae/generated_00.png?se=2024-06-13T11%3A43%3A22Z&sig=6bleQdhXuf%2FNy1O9VALc%2FLZdwXfi1bSIu3yGP%2BNFQf0%3D&ske=2024-06-19T01%3A28%3A16Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2024-06-12T01%3A28%3A16Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\"}]}\n",
            "An x-ray image showcasing the human chest. The radiography must consist of the sternum (breastbone) in the center, the ribcage surrounding it, the clavicle (collarbone) at the top, and the heart and lungs visible as darker areas. The lung fields must look symmetrical on each side. The faint white branching structures might be the bronchial tree. The image contains shades of grey, where denser structures like the bone appear whiter. The setting must elude a radiology department with the x-ray positioned on an illuminated panel for viewing.\n",
            "https://dalleproduse.blob.core.windows.net/private/images/e41b776c-27a5-43f3-b527-a98be3068dae/generated_00.png?se=2024-06-13T11%3A43%3A22Z&sig=6bleQdhXuf%2FNy1O9VALc%2FLZdwXfi1bSIu3yGP%2BNFQf0%3D&ske=2024-06-19T01%3A28%3A16Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2024-06-12T01%3A28%3A16Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\n",
            "https://dalleproduse.blob.core.windows.net/private/images/e41b776c-27a5-43f3-b527-a98be3068dae/generated_00.png?se=2024-06-13T11%3A43%3A22Z&sig=6bleQdhXuf%2FNy1O9VALc%2FLZdwXfi1bSIu3yGP%2BNFQf0%3D&ske=2024-06-19T01%3A28%3A16Z&skoid=09ba021e-c417-441c-b203-c81e5dcd7b7f&sks=b&skt=2024-06-12T01%3A28%3A16Z&sktid=33e01921-4d64-4f8c-a055-5bdaffd5e33d&skv=2020-10-02&sp=r&spr=https&sr=b&sv=2020-10-02\n",
            "Enter 1 to chat 2 to generate image 3 to exit\n",
            "Enter your choice: 1\n",
            "Enter user message: how to do x-ray of human?\n",
            "Sending request to Azure OpenAI model...\n",
            "Response:To perform an X-ray examination on a human, follow these steps:\n",
            "\n",
            "1. Prepare the patient: Ensure the patient is wearing appropriate clothing, free of any metal objects or jewelry that may interfere with the X-ray image. Provide a gown if necessary.\n",
            "\n",
            "2. Position the patient: Depending on the area to be examined, position the patient accordingly. For example, if examining the chest, have the patient stand facing the X-ray machine with their hands on their hips.\n",
            "\n",
            "3. Protect the patient: Cover the patient with a lead apron to shield them from unnecessary radiation exposure. Ensure that any body parts not being examined are properly shielded.\n",
            "\n",
            "4. Position the X-ray machine: Adjust the X-ray machine so that it is correctly aligned with the area to be examined. This may involve moving the machine or the patient.\n",
            "\n",
            "5. Collaborate with the radiographer: If you are not a trained radiographer, work closely with one to ensure proper technique and positioning.\n",
            "\n",
            "6. Take the X-ray: Instruct the patient to hold still and remain in the desired position while the X-ray is taken. The radiographer will activate the X-ray machine from a separate room.\n",
            "\n",
            "7. Repeat if necessary: Additional X-rays may be needed from different angles or positions to obtain a complete view of the area of interest.\n",
            "\n",
            "8. Review the images: Once the X-rays are taken, the radiographer will develop the films or upload the digital images for review. Consult with a radiologist or trained medical professional to interpret the results.\n",
            "\n",
            "Please note that performing X-rays requires proper training and certification. It is important to consult with a qualified healthcare professional or radiographer to ensure accurate and safe X-ray examinations.\n",
            "\n",
            "Enter 1 to chat 2 to generate image 3 to exit\n",
            "Enter your choice: 3\n",
            "Exiting program...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vjlt888PjTW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}